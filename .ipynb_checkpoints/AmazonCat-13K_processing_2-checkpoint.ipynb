{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /usr/local/lib/python3.6/dist-packages (20.0.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.0.1)\r\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2019.3)\r\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.13.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.22.1)\r\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.4.1)\r\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.14.1)\r\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.18.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.8.1)\n",
      "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.13.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.18.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.9.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.8.1->gensim) (2.22.0)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.8.1->gensim) (1.12.5)\n",
      "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/lib/python3/dist-packages (from requests->smart-open>=1.8.1->gensim) (2.6)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (1.25.7)\n",
      "Requirement already satisfied: botocore<1.16.0,>=1.15.5 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.8.1->gensim) (1.15.5)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.8.1->gensim) (0.9.4)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.8.1->gensim) (0.3.3)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.5->boto3->smart-open>=1.8.1->gensim) (2.8.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.5->boto3->smart-open>=1.8.1->gensim) (0.15.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create embedding matrix\n",
    "We'll use the word2vec module from gensim to create an embedding matrix that can be used by tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import savez_compressed\n",
    "import ast\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import datetime\n",
    "from gensim.models.word2vec import FAST_VERSION\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the data\n",
    "data_list = [a, b, c, d, e, f, g, h, i ,f] = [None, None, None, None, None, None, None, None, None, None]\n",
    "data_location = '../Datasets/AmazonCat-13K/processed/' \n",
    "for i in range(len(data_list)):\n",
    "    data_list[i] = pd.read_csv(data_location + f'first_pass_no{i + 1}.csv', encoding='latin1')\n",
    "    \n",
    "# Concatenate all the data and reset the index\n",
    "data = pd.concat(data_list, sort=False)\n",
    "data = data.reset_index()\n",
    "\n",
    "# Delete unused var (to save memory)\n",
    "del data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the labels from string to array (return unique values only)\n",
    "data['labels'] = data['labels'].apply(lambda labels: list(set(ast.literal_eval(labels))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values\n",
    "data = data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to join title and description\n",
    "def join_title_and_description(row):\n",
    "    return f'{row[\"title\"]} {row[\"description\"]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column that combines the title and description\n",
    "data['title_and_description'] = data.apply(lambda row: join_title_and_description(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop title and description columns (to save memory)\n",
    "data = data.drop(labels=['title', 'description'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1494407, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have a look at the shape\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>item_id</th>\n",
       "      <th>labels</th>\n",
       "      <th>title_and_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ID:B0027DQHA0</td>\n",
       "      <td>[Movies &amp; TV, Music, TV, Classical]</td>\n",
       "      <td>Sao Paulo Samba (2008) Conducted by John Nesch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ID:0756400120</td>\n",
       "      <td>[Short Stories, United States, Anthologies, Sc...</td>\n",
       "      <td>Past Imperfect (Daw Book Collectors) This fast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ID:B00024YAOQ</td>\n",
       "      <td>[Books, Motivation &amp; Self-Improvement, Busines...</td>\n",
       "      <td>Winning Every Time: How to Use the Skills of a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        item_id                                             labels  \\\n",
       "0      0  ID:B0027DQHA0                [Movies & TV, Music, TV, Classical]   \n",
       "1      1  ID:0756400120  [Short Stories, United States, Anthologies, Sc...   \n",
       "2      2  ID:B00024YAOQ  [Books, Motivation & Self-Improvement, Busines...   \n",
       "\n",
       "                               title_and_description  \n",
       "0  Sao Paulo Samba (2008) Conducted by John Nesch...  \n",
       "1  Past Imperfect (Daw Book Collectors) This fast...  \n",
       "2  Winning Every Time: How to Use the Skills of a...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have a look at the first 3 rows\n",
    "data.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from df to list so it can be processed\n",
    "text = data['title_and_description'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the data\n",
    "VOCAB_SIZE = 200000\n",
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a squence from the tokens\n",
    "sequences = tokenizer.texts_to_sequences(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unused var (to save memory)\n",
    "del text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29260, 21551, 12365, 3328, 4450, 19, 237, 211, 1219, 1, 2781, 7, 2982, 19, 55, 28920, 6087, 3, 1991, 100, 123, 181, 1, 2781, 264, 301, 5176, 1, 3727, 9, 16, 13217, 1255, 3, 6394, 2, 1991, 100, 1500, 131, 499]\n"
     ]
    }
   ],
   "source": [
    "# Have a look at the first sequence\n",
    "print(sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sequence of integers to sequence of tokens so they can be processed by Word2Vec\n",
    "stringified_sequences = []\n",
    "# for sequence in padded_sequences:\n",
    "for sequence in sequences:\n",
    "    stringified_sequence = [str(index) for index in sequence]\n",
    "    stringified_sequences.append(stringified_sequence)\n",
    "    del stringified_sequence # to save memory??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['29260', '21551', '12365', '3328', '4450', '19', '237', '211', '1219', '1', '2781', '7', '2982', '19', '55', '28920', '6087', '3', '1991', '100', '123', '181', '1', '2781', '264', '301', '5176', '1', '3727', '9', '16', '13217', '1255', '3', '6394', '2', '1991', '100', '1500', '131', '499']\n"
     ]
    }
   ],
   "source": [
    "# Have a look at the first sequence of tokens\n",
    "print(stringified_sequences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the word2vec word vectors\n",
    "In his original CNN-Kim paper, the author used a pre-trained word2vec embedding developed by Google. They provided the link but it's broken. So, we'll create our own word2vec embeddings for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check gensim version used\n",
    "FAST_VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create loss store\n",
    "loss_store = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callback function\n",
    "class callback(CallbackAny2Vec):\n",
    "    '''Callback to print loss after each epoch.'''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.epoch = 1\n",
    "        self.previous_cumulative_loss = 0\n",
    "        self.start_time = 0\n",
    "    \n",
    "    def on_epoch_begin(self, model):\n",
    "        self.start_time = datetime.datetime.now()\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        cumulative_loss = model.get_latest_training_loss()\n",
    "        loss_now = cumulative_loss - self.previous_cumulative_loss\n",
    "        loss_store.append(loss_now)\n",
    "        self.previous_cumulative_loss = cumulative_loss\n",
    "        \n",
    "        end_time = datetime.datetime.now()\n",
    "        time_taken_seconds = (end_time - self.start_time).total_seconds()\n",
    "        minutes = int(time_taken_seconds // 60)\n",
    "        if minutes < 10:\n",
    "            minutes = '0' + str(minutes)\n",
    "        seconds = round(time_taken_seconds % 60)\n",
    "        if seconds < 10:\n",
    "            seconds = '0' + str(seconds)\n",
    "        \n",
    "        print(f'{self.epoch} ----- {loss_now} ----- {minutes}:{seconds}')\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch ----- Loss ----- Time\n",
      "1 ----- 31120102.0 ----- 02:23\n",
      "2 ----- 18646554.0 ----- 02:23\n",
      "3 ----- 17485496.0 ----- 02:22\n",
      "4 ----- 4078240.0 ----- 02:21\n",
      "5 ----- 4113040.0 ----- 02:22\n",
      "6 ----- 4088168.0 ----- 02:23\n",
      "7 ----- 4071240.0 ----- 02:23\n",
      "8 ----- 3991568.0 ----- 02:22\n",
      "9 ----- 3929952.0 ----- 02:23\n",
      "10 ----- 3830904.0 ----- 02:22\n",
      "11 ----- 3736880.0 ----- 02:22\n",
      "12 ----- 3593552.0 ----- 02:22\n",
      "13 ----- 3461640.0 ----- 02:23\n",
      "14 ----- 3298064.0 ----- 02:22\n",
      "15 ----- 3112368.0 ----- 02:23\n",
      "16 ----- 2894704.0 ----- 02:23\n",
      "17 ----- 2630072.0 ----- 02:22\n",
      "18 ----- 2331512.0 ----- 02:23\n",
      "19 ----- 1985128.0 ----- 02:23\n",
      "20 ----- 1590864.0 ----- 02:23\n"
     ]
    }
   ],
   "source": [
    "# Train the word2vec word vectors (100 dimensions)\n",
    "EMBEDDING_DIMENSION = 100\n",
    "print(f'Epoch ----- Loss ----- Time')\n",
    "word_vectors = Word2Vec(sentences = stringified_sequences,\n",
    "                        sg = 0, # 0 for continuous bag of words model, 1 for skip-gram model\n",
    "                        size = EMBEDDING_DIMENSION, # Dimensionality of the word vectors\n",
    "                        window = 10, # Maximum distance between the current and predicted word within a sentence\n",
    "                        workers = 12, # Use these many worker threads to train the model \n",
    "                        compute_loss=True, \n",
    "                        callbacks=[callback()],\n",
    "                        iter = 20) # Run this many time through the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss at each itteration\n",
    "plt.plot(loss_store, label='loss');\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199999"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of tokens that have been trained for\n",
    "len(word_vectors.wv.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the dimensions of each token\n",
    "word_vectors.wv.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unused var (to save memory)\n",
    "del stringified_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the word2vec mapping to an embedding matrix\n",
    "An embedding matrix is the structure that TensorFlow will accept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty embedding matrix\n",
    "weight_matrix = np.zeros((VOCAB_SIZE, EMBEDDING_DIMENSION))\n",
    "\n",
    "# Fill the matrix with word vectors\n",
    "for i in range(VOCAB_SIZE - 1):\n",
    "    weight_matrix[i + 1] = word_vectors.wv[str(i + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the embedding matrix shape\n",
    "weight_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the embedding matrix to use for later\n",
    "save_path = '../Datasets/AmazonCat-13K/processed/'\n",
    "savez_compressed(save_path + 'embedding_matrix.npz', weight_matrix)\n",
    "# np.savetxt(save_path + 'embedding_matrix.csv', weight_matrix, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unused var (to save memory)\n",
    "del weight_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save a new dataset with the tokenized title and description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty dataframe\n",
    "tokenized_data = pd.DataFrame(columns = ['item_id', 'tokenized_title_and_description', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the data\n",
    "tokenized_data['item_id'] = data['item_id'].copy()\n",
    "tokenized_data['tokenized_title_and_description'] = sequences # This is the integer version\n",
    "tokenized_data['labels'] = data['labels'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1494407, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of the dataframe\n",
    "tokenized_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>tokenized_title_and_description</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID:B0027DQHA0</td>\n",
       "      <td>[29260, 21551, 12365, 3328, 4450, 19, 237, 211...</td>\n",
       "      <td>[Movies &amp; TV, Music, TV, Classical]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID:0756400120</td>\n",
       "      <td>[381, 15160, 38609, 41, 5949, 10, 477, 1179, 3...</td>\n",
       "      <td>[Short Stories, United States, Anthologies, Sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID:B00024YAOQ</td>\n",
       "      <td>[646, 150, 56, 73, 5, 99, 1, 883, 3, 4, 3470, ...</td>\n",
       "      <td>[Books, Motivation &amp; Self-Improvement, Busines...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         item_id                    tokenized_title_and_description  \\\n",
       "0  ID:B0027DQHA0  [29260, 21551, 12365, 3328, 4450, 19, 237, 211...   \n",
       "1  ID:0756400120  [381, 15160, 38609, 41, 5949, 10, 477, 1179, 3...   \n",
       "2  ID:B00024YAOQ  [646, 150, 56, 73, 5, 99, 1, 883, 3, 4, 3470, ...   \n",
       "\n",
       "                                              labels  \n",
       "0                [Movies & TV, Music, TV, Classical]  \n",
       "1  [Short Stories, United States, Anthologies, Sc...  \n",
       "2  [Books, Motivation & Self-Improvement, Busines...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have a look at the first 3 rows\n",
    "tokenized_data.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column of token counts\n",
    "tokenized_data['token_count'] = tokenized_data['tokenized_title_and_description'].apply(lambda tokens: len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for rows with missing values\n",
    "len(tokenized_data[tokenized_data['token_count'] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing values\n",
    "tokenized_data = tokenized_data[tokenized_data.token_count != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove column of token counts\n",
    "tokenized_data = tokenized_data.drop('token_count', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1494364, 3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of the dataframe\n",
    "tokenized_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index\n",
    "tokenized_data = tokenized_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>tokenized_title_and_description</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID:B0027DQHA0</td>\n",
       "      <td>[29260, 21551, 12365, 3328, 4450, 19, 237, 211...</td>\n",
       "      <td>[Movies &amp; TV, Music, TV, Classical]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID:0756400120</td>\n",
       "      <td>[381, 15160, 38609, 41, 5949, 10, 477, 1179, 3...</td>\n",
       "      <td>[Short Stories, United States, Anthologies, Sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID:B00024YAOQ</td>\n",
       "      <td>[646, 150, 56, 73, 5, 99, 1, 883, 3, 4, 3470, ...</td>\n",
       "      <td>[Books, Motivation &amp; Self-Improvement, Busines...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         item_id                    tokenized_title_and_description  \\\n",
       "0  ID:B0027DQHA0  [29260, 21551, 12365, 3328, 4450, 19, 237, 211...   \n",
       "1  ID:0756400120  [381, 15160, 38609, 41, 5949, 10, 477, 1179, 3...   \n",
       "2  ID:B00024YAOQ  [646, 150, 56, 73, 5, 99, 1, 883, 3, 4, 3470, ...   \n",
       "\n",
       "                                              labels  \n",
       "0                [Movies & TV, Music, TV, Classical]  \n",
       "1  [Short Stories, United States, Anthologies, Sc...  \n",
       "2  [Books, Motivation & Self-Improvement, Busines...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have a look at the first 3 rows\n",
    "tokenized_data.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create save_as_csv function\n",
    "def save_as_csv(df, path):\n",
    "    df.to_csv(path, \n",
    "              header=True, \n",
    "              index=None, \n",
    "              encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as csv (broken up into 5 files)\n",
    "num_files = 10\n",
    "size = tokenized_data.shape[0] // num_files\n",
    "for file_num in range(num_files):\n",
    "    if file_num == 0:\n",
    "        save_as_csv(tokenized_data[:size], save_path + f'tokenized_no{file_num + 1}.csv')\n",
    "    elif file_num == (num_files - 1):\n",
    "        save_as_csv(tokenized_data[size * file_num:], save_path + f'tokenized_no{file_num + 1}.csv')\n",
    "    else:\n",
    "        save_as_csv(tokenized_data[size * file_num: size * (file_num + 1)], save_path + f'tokenized_no{file_num + 1}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
