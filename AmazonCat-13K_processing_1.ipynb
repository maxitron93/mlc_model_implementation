{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data comes in three text files:\n",
    "\n",
    "- titles.txt\n",
    "- desciptions.txt\n",
    "- categories.txt <em>(labels)</em>\n",
    "\n",
    "They need to be processed into a single csv with the following columns <em>(all strings)</em>:\n",
    "- item_id \n",
    "- title\n",
    "- description\n",
    "- labels\n",
    "\n",
    "This will allow us to more easilt process the data further down the line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import re\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create string of data location\n",
    "data_location = '../Datasets/AmazonCat-13K/raw/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the labels\n",
    "f_labels = open(data_location + 'categories.txt', encoding='latin1')\n",
    "labels = f_labels.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B0027DQHA0\n",
      "  Movies & TV, TV\n",
      "  Music, Classical\n",
      "0756400120\n",
      "  Books, Literature & Fiction, Anthologies & Literary Collections, General\n",
      "  Books, Literature & Fiction, United States\n",
      "  Books, Science Fiction & Fantasy, Science Fiction, Anthologies\n",
      "  Books, Science Fiction & Fantasy, Science Fiction, Sho\n"
     ]
    }
   ],
   "source": [
    "# Show the first 300 Characters\n",
    "print(labels[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the file\n",
    "f_labels.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a dictionary of the item_id to its labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with empty id_labels_dict and item_id placeholder\n",
    "item_id = ''\n",
    "id_labels_dict = {}\n",
    "labels_ids_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file, loop through each line, and process them as either an item_id or label\n",
    "with open(data_location + 'categories.txt', encoding='latin1') as labels_file:\n",
    "    for line in labels_file:\n",
    "        if not re.match(' ', line): # If it doesn't start with ' ', it's an item_id\n",
    "            item_id = line.strip()\n",
    "            labels_ids_count += 1\n",
    "        else:\n",
    "            # If this isn't the first label for the item_id, add the label to existing labels\n",
    "            if item_id in id_labels_dict: \n",
    "                id_labels_dict[item_id] += [label.strip() for label in line.split(',')] \n",
    "            # If this is the first label for the item_id, add the item_id to the dict with the label\n",
    "            else: \n",
    "                id_labels_dict[item_id] = [label.strip() for label in line.split(',')]\n",
    "    # Close the file\n",
    "    labels_file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels count: 2441053\n"
     ]
    }
   ],
   "source": [
    "# Have a look at the ids count\n",
    "print(f'Labels count: {labels_ids_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Movies & TV', 'TV', 'Music', 'Classical']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have a look at the first item\n",
    "id_labels_dict['B0027DQHA0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the titles\n",
    "f_titles = open(data_location + 'titles.txt', encoding='latin1')\n",
    "titles = f_titles.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B00308CJ12 Bulletproof Salesman (2008)\n",
      "189138922X Classical Mechanics\n",
      "B0000CEP9J Fiesta Black 464 7-1/4-inch Salad Plate\n",
      "B000HRH6IA Baby Blue Aurora Blue Gem Butterfly Belly Ring\n",
      "B000002ERY Predicciones Leo\n",
      "B000JM2796 Shakespeare Synergy Supreme Rear Drag Spin Reel, 5435R\n",
      "0570070538 The Very First E\n"
     ]
    }
   ],
   "source": [
    "# Show the first 300 Characters\n",
    "print(titles[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the file\n",
    "f_titles.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a dictionary of item_id to its title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dictionary\n",
    "id_title_dict = {}\n",
    "title_ids_count = 0\n",
    "titles_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file, loop through each line, and process the content as an item_id or title\n",
    "with open(data_location + 'titles.txt', encoding='latin1') as titles_file:\n",
    "    for line in titles_file:\n",
    "        line = line.strip()\n",
    "        splitted_line = line.split(' ')\n",
    "        item_id = splitted_line[0]\n",
    "        title_ids_count += 1\n",
    "        title = (' '.join(splitted_line[1:]))\n",
    "        titles_count += 1\n",
    "        id_title_dict[item_id] = title\n",
    "    titles_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDs count: 1720307\n",
      "Titles count: 1720307\n"
     ]
    }
   ],
   "source": [
    "# Have a look at the ids and titles count\n",
    "print(f'IDs count: {title_ids_count}')\n",
    "print(f'Titles count: {titles_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bulletproof Salesman (2008)'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have a look at the first item\n",
    "id_title_dict['B00308CJ12']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the descriptions\n",
    "f_descs = open(data_location + 'descriptions.txt', encoding='latin1')\n",
    "descs = f_descs.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product/productId: B0027DQHA0\n",
      "product/description: Conducted by John Neschling since 1997, the orchestra is defined by its emblematic interpretations of Latin American music. Here the orchestra yet again grips the listener with an electrifying selection of Brazilian and Latin American classics including w\n",
      "\n",
      "product/productId: 0756400120\n",
      "product/description: This fast, lightweight anthology of 12 time-travel tales contains a handful of standout stories, but many others rely on familiar tricks: Will the hero change his destiny by changing his past? Will the hero realize that that sound he heard all those years ago was his meddling future self? The most successful stories toy with genre conventions or use time travel as a device in support of bigger concerns. James P. Hogan's slyly amusing \"Convolution\" focuses on time-machine inventor Professor Abercrombie. The professor loses his notes before completing his machine, but a future version of himself sends a time machine back, embroiling Ab\n"
     ]
    }
   ],
   "source": [
    "# Show the first 1000 Characters\n",
    "print(descs[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the file\n",
    "f_descs.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a dictionary of item_id to its description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_desc_dict = {}\n",
    "desc_id_count = 0\n",
    "descs_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_id = ''\n",
    "description = ''\n",
    "# Open the file, loop through each line, and process the content as an item_id or title\n",
    "with open(data_location + 'descriptions.txt', encoding='latin1') as descs_file:\n",
    "    for line in descs_file:\n",
    "        line = line.strip()\n",
    "        if item_id != '' and description != '':\n",
    "            if item_id not in id_desc_dict:\n",
    "                desc_id_count += 1\n",
    "                descs_count += 1\n",
    "                id_desc_dict[item_id] = description\n",
    "            item_id = ''\n",
    "            description = ''\n",
    "        elif 'product/productId' in line:\n",
    "            item_id = line[19:]\n",
    "        elif 'product/description' in line:\n",
    "            description = line[21:]\n",
    "    descs_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: For one item, with id 0070134561, half the description is missing because it's on the next line. Only this one item has this 'error'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID count: 1494801\n",
      "Description count: 1494801\n"
     ]
    }
   ],
   "source": [
    "# Have a look at the ids and descriptions count\n",
    "print(f'ID count: {desc_id_count}')\n",
    "print(f'Description count: {descs_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Conducted by John Neschling since 1997, the orchestra is defined by its emblematic interpretations of Latin American music. Here the orchestra yet again grips the listener with an electrifying selection of Brazilian and Latin American classics including w'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have a look at the first item\n",
    "id_desc_dict['B0027DQHA0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure out which items have missing information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titles count: 1720307\n",
      "Descriptions count: 1494801\n",
      "Labels count: 2441053\n"
     ]
    }
   ],
   "source": [
    "# Have a look at the counts of each type of information\n",
    "print(f'Titles count: {titles_count}')\n",
    "print(f'Descriptions count: {descs_count}')\n",
    "print(f'Labels count: {labels_ids_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of labels with not titles or descriotions. But after looking at papers that use AmazonCat-13K, it looks like they use only 1,493,021 instances of the data. It's likely they discarded items that are missing the title, description, or both. Most of the information is contained in the descriptions, so let's see how the descriptions match up with the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create var with starting value of 0\n",
    "has_desc_and_labels = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in id_desc_dict.keys():\n",
    "    try:\n",
    "        id_labels_dict[key]\n",
    "        has_desc_and_labels += 1\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has description and labels: 1494801\n"
     ]
    }
   ],
   "source": [
    "print(f'Has description and labels: {has_desc_and_labels}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All items with a description has labels. But that's still higher than the reported 1,493,021 instances used by the papers. Let's see how many of these items have titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create var with starting value of 0\n",
    "has_desc_and_labels_and_title = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in id_desc_dict.keys():\n",
    "    try:\n",
    "        id_labels_dict[key]\n",
    "        try:\n",
    "            id_title_dict[key]\n",
    "            has_desc_and_labels_and_title += 1\n",
    "        except:\n",
    "            pass\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has description and labels and title: 1053117\n"
     ]
    }
   ],
   "source": [
    "print(f'Has description and labels and title: {has_desc_and_labels_and_title}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's not enough. So the 'title' probably didn't get used in the other papers. Now lets see if there are any with no descriptions or labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create var with starting value of 0\n",
    "has_non_empty_desc_and_labels = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in id_desc_dict.keys():\n",
    "    if len(id_desc_dict[key]) > 0:\n",
    "        try:\n",
    "            labels = id_labels_dict[key]\n",
    "            if len(labels) > 0:\n",
    "                has_non_empty_desc_and_labels += 1\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has non-empty description and labels and title: 1494801\n"
     ]
    }
   ],
   "source": [
    "print(f'Has non-empty description and labels and title: {has_non_empty_desc_and_labels}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No change. They all have some value for descriptions and labels. I guess being a little bit off isn't too bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of lists\n",
    "items_list = []\n",
    "for key, value in id_desc_dict.items():\n",
    "    title = 'NO_TITLE'\n",
    "    if key in id_title_dict:\n",
    "        title = id_title_dict[key]\n",
    "    items_list.append(['ID:' + key, title, value, id_labels_dict[key]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of lists to a DataFrame\n",
    "processed_data = pd.DataFrame(items_list, columns = ['item_id', 'title', 'description', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1494801"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have a look at the shape of the dataframe\n",
    "nrows = processed_data.shape[0]\n",
    "nrows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ID:B0027DQHA0</td>\n",
       "      <td>Sao Paulo Samba (2008)</td>\n",
       "      <td>Conducted by John Neschling since 1997, the or...</td>\n",
       "      <td>[Movies &amp; TV, TV, Music, Classical]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ID:0756400120</td>\n",
       "      <td>Past Imperfect (Daw Book Collectors)</td>\n",
       "      <td>This fast, lightweight anthology of 12 time-tr...</td>\n",
       "      <td>[Books, Literature &amp; Fiction, Anthologies &amp; Li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ID:B00024YAOQ</td>\n",
       "      <td>Winning Every Time: How to Use the Skills of a...</td>\n",
       "      <td>Whether you're hoping to obtain a raise from y...</td>\n",
       "      <td>[Books, Business &amp; Investing, Business Life, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ID:B000BUGXAU</td>\n",
       "      <td>Nano Cube 24 Gallon Deluxe</td>\n",
       "      <td>Just add water!\\tThe Nano Cube is a 24-gallon ...</td>\n",
       "      <td>[Pet Supplies, Fish &amp; Aquatic Pets, Aquariums]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ID:B0007YMWC8</td>\n",
       "      <td>Asalto En Tijuana (2005)</td>\n",
       "      <td>An honest citizen is forced to steal the world...</td>\n",
       "      <td>[Movies &amp; TV, Movies]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         item_id                                              title  \\\n",
       "0  ID:B0027DQHA0                             Sao Paulo Samba (2008)   \n",
       "1  ID:0756400120               Past Imperfect (Daw Book Collectors)   \n",
       "2  ID:B00024YAOQ  Winning Every Time: How to Use the Skills of a...   \n",
       "3  ID:B000BUGXAU                         Nano Cube 24 Gallon Deluxe   \n",
       "4  ID:B0007YMWC8                           Asalto En Tijuana (2005)   \n",
       "\n",
       "                                         description  \\\n",
       "0  Conducted by John Neschling since 1997, the or...   \n",
       "1  This fast, lightweight anthology of 12 time-tr...   \n",
       "2  Whether you're hoping to obtain a raise from y...   \n",
       "3  Just add water!\\tThe Nano Cube is a 24-gallon ...   \n",
       "4  An honest citizen is forced to steal the world...   \n",
       "\n",
       "                                              labels  \n",
       "0                [Movies & TV, TV, Music, Classical]  \n",
       "1  [Books, Literature & Fiction, Anthologies & Li...  \n",
       "2  [Books, Business & Investing, Business Life, M...  \n",
       "3     [Pet Supplies, Fish & Aquatic Pets, Aquariums]  \n",
       "4                              [Movies & TV, Movies]  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have a look at the first 5 rows\n",
    "processed_data.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the dataframe as csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create save_as_csv function\n",
    "def save_as_csv(df, path):\n",
    "    df.to_csv(path, \n",
    "              header=True, \n",
    "              index=None, \n",
    "              encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as csv (broken up into 5 files)\n",
    "num_files = 10\n",
    "size = nrows // num_files\n",
    "save_path = '../Datasets/AmazonCat-13K/processed/first_pass'\n",
    "for file_num in range(num_files):\n",
    "    if file_num == 0:\n",
    "        save_as_csv(processed_data[:size], save_path + f'_no{file_num + 1}.csv')\n",
    "    elif file_num == (num_files - 1):\n",
    "        save_as_csv(processed_data[size * file_num:], save_path + f'_no{file_num + 1}.csv')\n",
    "    else:\n",
    "        save_as_csv(processed_data[size * file_num: size * (file_num + 1)], save_path + f'_no{file_num + 1}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
