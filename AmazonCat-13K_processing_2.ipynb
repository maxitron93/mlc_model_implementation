{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /usr/local/lib/python3.6/dist-packages (20.0.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.13.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.22.1)\r\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.14.1)\r\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.4.1)\r\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.18.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.8.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.9.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.13.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.18.1)\n",
      "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.8.1->gensim) (1.12.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.8.1->gensim) (2.22.0)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.8.1->gensim) (0.3.3)\n",
      "Requirement already satisfied: botocore<1.16.0,>=1.15.5 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.8.1->gensim) (1.15.5)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.8.1->gensim) (0.9.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/lib/python3/dist-packages (from requests->smart-open>=1.8.1->gensim) (2.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (1.25.7)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.5->boto3->smart-open>=1.8.1->gensim) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.5->boto3->smart-open>=1.8.1->gensim) (2.8.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create embedding matrix\n",
    "We'll use the word2vec module from gensim to create an embedding matrix that can be used by tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import savez_compressed\n",
    "import ast\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import datetime\n",
    "from gensim.models.word2vec import FAST_VERSION\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the data\n",
    "data_list = [a, b, c, d, e, f, g, h, i ,f] = [None, None, None, None, None, None, None, None, None, None]\n",
    "data_location = '../Datasets/AmazonCat-13K/processed/' \n",
    "for i in range(len(data_list)):\n",
    "    data_list[i] = pd.read_csv(data_location + f'first_pass_no{i + 1}.csv', encoding='latin1')\n",
    "    \n",
    "# Concatenate all the data and reset the index\n",
    "data = pd.concat(data_list, sort=False)\n",
    "data = data.reset_index()\n",
    "\n",
    "# Delete unused var (to save memory)\n",
    "del data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the labels from string to array (return unique values only)\n",
    "data['labels'] = data['labels'].apply(lambda labels: list(set(ast.literal_eval(labels))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values\n",
    "data = data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to join title and description\n",
    "def join_title_and_description(row):\n",
    "    return f'{row[\"title\"]} {row[\"description\"]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column that combines the title and description\n",
    "data['title_and_description'] = data.apply(lambda row: join_title_and_description(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop title and description columns (to save memory)\n",
    "data = data.drop(labels=['title', 'description'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1494407, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have a look at the shape\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>item_id</th>\n",
       "      <th>labels</th>\n",
       "      <th>title_and_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ID:B0027DQHA0</td>\n",
       "      <td>[TV, Music, Classical, Movies &amp; TV]</td>\n",
       "      <td>Sao Paulo Samba (2008) Conducted by John Nesch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ID:0756400120</td>\n",
       "      <td>[Literature &amp; Fiction, United States, Books, S...</td>\n",
       "      <td>Past Imperfect (Daw Book Collectors) This fast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ID:B00024YAOQ</td>\n",
       "      <td>[Business Life, Motivation &amp; Self-Improvement,...</td>\n",
       "      <td>Winning Every Time: How to Use the Skills of a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        item_id                                             labels  \\\n",
       "0      0  ID:B0027DQHA0                [TV, Music, Classical, Movies & TV]   \n",
       "1      1  ID:0756400120  [Literature & Fiction, United States, Books, S...   \n",
       "2      2  ID:B00024YAOQ  [Business Life, Motivation & Self-Improvement,...   \n",
       "\n",
       "                               title_and_description  \n",
       "0  Sao Paulo Samba (2008) Conducted by John Nesch...  \n",
       "1  Past Imperfect (Daw Book Collectors) This fast...  \n",
       "2  Winning Every Time: How to Use the Skills of a...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have a look at the first 3 rows\n",
    "data.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from df to list so it can be processed\n",
    "text = data['title_and_description'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the data\n",
    "VOCAB_SIZE = 200000\n",
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a squence from the tokens\n",
    "sequences = tokenizer.texts_to_sequences(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unused var (to save memory)\n",
    "del text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29260, 21551, 12365, 3328, 4450, 19, 237, 211, 1219, 1, 2781, 7, 2982, 19, 55, 28920, 6087, 3, 1991, 100, 123, 181, 1, 2781, 264, 301, 5176, 1, 3727, 9, 16, 13217, 1255, 3, 6394, 2, 1991, 100, 1500, 131, 499]\n"
     ]
    }
   ],
   "source": [
    "# Have a look at the first sequence\n",
    "print(sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sequence of integers to sequence of tokens so they can be processed by Word2Vec\n",
    "stringified_sequences = []\n",
    "# for sequence in padded_sequences:\n",
    "for sequence in sequences:\n",
    "    stringified_sequence = [str(index) for index in sequence]\n",
    "    stringified_sequences.append(stringified_sequence)\n",
    "    del stringified_sequence # to save memory??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['29260', '21551', '12365', '3328', '4450', '19', '237', '211', '1219', '1', '2781', '7', '2982', '19', '55', '28920', '6087', '3', '1991', '100', '123', '181', '1', '2781', '264', '301', '5176', '1', '3727', '9', '16', '13217', '1255', '3', '6394', '2', '1991', '100', '1500', '131', '499']\n"
     ]
    }
   ],
   "source": [
    "# Have a look at the first sequence of tokens\n",
    "print(stringified_sequences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the word2vec word vectors\n",
    "In his original CNN-Kim paper, the author used a pre-trained word2vec embedding developed by Google. They provided the link but it's broken. So, we'll create our own word2vec embeddings for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check gensim version used\n",
    "FAST_VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create loss store\n",
    "loss_store = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callback function\n",
    "class callback(CallbackAny2Vec):\n",
    "    '''Callback to print loss after each epoch.'''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.epoch = 1\n",
    "        self.previous_cumulative_loss = 0\n",
    "        self.start_time = 0\n",
    "    \n",
    "    def on_epoch_begin(self, model):\n",
    "        self.start_time = datetime.datetime.now()\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        cumulative_loss = model.get_latest_training_loss()\n",
    "        loss_now = cumulative_loss - self.previous_cumulative_loss\n",
    "        loss_store.append(loss_now)\n",
    "        self.previous_cumulative_loss = cumulative_loss\n",
    "        \n",
    "        end_time = datetime.datetime.now()\n",
    "        time_taken_seconds = (end_time - self.start_time).total_seconds()\n",
    "        minutes = int(time_taken_seconds // 60)\n",
    "        if minutes < 10:\n",
    "            minutes = '0' + str(minutes)\n",
    "        seconds = round(time_taken_seconds % 60)\n",
    "        if seconds < 10:\n",
    "            seconds = '0' + str(seconds)\n",
    "        \n",
    "        print(f'{self.epoch} ----- {loss_now} ----- {minutes}:{seconds}')\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch ----- Loss ----- Time\n",
      "1 ----- 29372442.0 ----- 02:33\n",
      "2 ----- 18459182.0 ----- 02:33\n",
      "3 ----- 17172192.0 ----- 02:32\n",
      "4 ----- 5853488.0 ----- 02:32\n",
      "5 ----- 4276736.0 ----- 02:32\n",
      "6 ----- 4251704.0 ----- 02:32\n",
      "7 ----- 4190864.0 ----- 02:31\n",
      "8 ----- 4148288.0 ----- 02:32\n",
      "9 ----- 4064368.0 ----- 02:32\n",
      "10 ----- 3961800.0 ----- 02:32\n",
      "11 ----- 3845496.0 ----- 02:31\n",
      "12 ----- 3716160.0 ----- 02:32\n",
      "13 ----- 3568448.0 ----- 02:32\n",
      "14 ----- 3400792.0 ----- 02:32\n",
      "15 ----- 3204800.0 ----- 02:33\n",
      "16 ----- 3029624.0 ----- 02:32\n",
      "17 ----- 2759608.0 ----- 02:32\n",
      "18 ----- 2476488.0 ----- 02:32\n",
      "19 ----- 2161080.0 ----- 02:32\n",
      "20 ----- 1829992.0 ----- 02:33\n"
     ]
    }
   ],
   "source": [
    "# Train the word2vec word vectors (150 dimensions)\n",
    "EMBEDDING_DIMENSION = 150\n",
    "print(f'Epoch ----- Loss ----- Time')\n",
    "word_vectors = Word2Vec(sentences = stringified_sequences,\n",
    "                        sg = 0, # 0 for continuous bag of words model, 1 for skip-gram model\n",
    "                        size = EMBEDDING_DIMENSION, # Dimensionality of the word vectors\n",
    "                        window = 5, # Maximum distance between the current and predicted word within a sentence\n",
    "                        workers = 12, # Use these many worker threads to train the model \n",
    "                        compute_loss=True, \n",
    "                        callbacks=[callback()],\n",
    "                        iter = 20) # Run this many time through the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss at each itteration\n",
    "plt.plot(loss_store, label='loss');\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199999"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of tokens that have been trained for\n",
    "len(word_vectors.wv.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the dimensions of each token\n",
    "word_vectors.wv.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unused var (to save memory)\n",
    "del stringified_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the word2vec mapping to an embedding matrix\n",
    "An embedding matrix is the structure that TensorFlow will accept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty embedding matrix\n",
    "weight_matrix = np.zeros((VOCAB_SIZE, EMBEDDING_DIMENSION))\n",
    "\n",
    "# Fill the matrix with word vectors\n",
    "for i in range(VOCAB_SIZE - 1):\n",
    "    weight_matrix[i + 1] = word_vectors.wv[str(i + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 150)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the embedding matrix shape\n",
    "weight_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the embedding matrix to use for later\n",
    "save_path = '../Datasets/AmazonCat-13K/processed/'\n",
    "savez_compressed(save_path + 'embedding_matrix.npz', weight_matrix)\n",
    "# np.savetxt(save_path + 'embedding_matrix.csv', weight_matrix, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unused var (to save memory)\n",
    "del weight_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save a new dataset with the tokenized title and description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty dataframe\n",
    "tokenized_data = pd.DataFrame(columns = ['item_id', 'tokenized_title_and_description', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the data\n",
    "tokenized_data['item_id'] = data['item_id'].copy()\n",
    "tokenized_data['tokenized_title_and_description'] = sequences # This is the integer version\n",
    "tokenized_data['labels'] = data['labels'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1494407, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of the dataframe\n",
    "tokenized_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>tokenized_title_and_description</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID:B0027DQHA0</td>\n",
       "      <td>[29260, 21551, 12365, 3328, 4450, 19, 237, 211...</td>\n",
       "      <td>[TV, Music, Classical, Movies &amp; TV]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID:0756400120</td>\n",
       "      <td>[381, 15160, 38609, 41, 5949, 10, 477, 1179, 3...</td>\n",
       "      <td>[Literature &amp; Fiction, United States, Books, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID:B00024YAOQ</td>\n",
       "      <td>[646, 150, 56, 73, 5, 99, 1, 883, 3, 4, 3470, ...</td>\n",
       "      <td>[Business Life, Motivation &amp; Self-Improvement,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         item_id                    tokenized_title_and_description  \\\n",
       "0  ID:B0027DQHA0  [29260, 21551, 12365, 3328, 4450, 19, 237, 211...   \n",
       "1  ID:0756400120  [381, 15160, 38609, 41, 5949, 10, 477, 1179, 3...   \n",
       "2  ID:B00024YAOQ  [646, 150, 56, 73, 5, 99, 1, 883, 3, 4, 3470, ...   \n",
       "\n",
       "                                              labels  \n",
       "0                [TV, Music, Classical, Movies & TV]  \n",
       "1  [Literature & Fiction, United States, Books, S...  \n",
       "2  [Business Life, Motivation & Self-Improvement,...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have a look at the first 3 rows\n",
    "tokenized_data.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column of token counts\n",
    "tokenized_data['token_count'] = tokenized_data['tokenized_title_and_description'].apply(lambda tokens: len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for rows with missing values\n",
    "len(tokenized_data[tokenized_data['token_count'] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing values\n",
    "tokenized_data = tokenized_data[tokenized_data.token_count != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove column of token counts\n",
    "tokenized_data = tokenized_data.drop('token_count', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1494364, 3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of the dataframe\n",
    "tokenized_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index\n",
    "tokenized_data = tokenized_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>tokenized_title_and_description</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID:B0027DQHA0</td>\n",
       "      <td>[29260, 21551, 12365, 3328, 4450, 19, 237, 211...</td>\n",
       "      <td>[TV, Music, Classical, Movies &amp; TV]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID:0756400120</td>\n",
       "      <td>[381, 15160, 38609, 41, 5949, 10, 477, 1179, 3...</td>\n",
       "      <td>[Literature &amp; Fiction, United States, Books, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID:B00024YAOQ</td>\n",
       "      <td>[646, 150, 56, 73, 5, 99, 1, 883, 3, 4, 3470, ...</td>\n",
       "      <td>[Business Life, Motivation &amp; Self-Improvement,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         item_id                    tokenized_title_and_description  \\\n",
       "0  ID:B0027DQHA0  [29260, 21551, 12365, 3328, 4450, 19, 237, 211...   \n",
       "1  ID:0756400120  [381, 15160, 38609, 41, 5949, 10, 477, 1179, 3...   \n",
       "2  ID:B00024YAOQ  [646, 150, 56, 73, 5, 99, 1, 883, 3, 4, 3470, ...   \n",
       "\n",
       "                                              labels  \n",
       "0                [TV, Music, Classical, Movies & TV]  \n",
       "1  [Literature & Fiction, United States, Books, S...  \n",
       "2  [Business Life, Motivation & Self-Improvement,...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have a look at the first 3 rows\n",
    "tokenized_data.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create save_as_csv function\n",
    "def save_as_csv(df, path):\n",
    "    df.to_csv(path, \n",
    "              header=True, \n",
    "              index=None, \n",
    "              encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as csv (broken up into 5 files)\n",
    "num_files = 10\n",
    "size = tokenized_data.shape[0] // num_files\n",
    "for file_num in range(num_files):\n",
    "    if file_num == 0:\n",
    "        save_as_csv(tokenized_data[:size], save_path + f'tokenized_no{file_num + 1}.csv')\n",
    "    elif file_num == (num_files - 1):\n",
    "        save_as_csv(tokenized_data[size * file_num:], save_path + f'tokenized_no{file_num + 1}.csv')\n",
    "    else:\n",
    "        save_as_csv(tokenized_data[size * file_num: size * (file_num + 1)], save_path + f'tokenized_no{file_num + 1}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
